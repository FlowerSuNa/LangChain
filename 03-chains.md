# LangChain - ì²´ì¸ (Chains) ê°œìš” 

- ì²´ì¸ì€ ì—¬ëŸ¬ êµ¬ì„±ìš”ì†Œ(í”„ë¡¬í”„íŠ¸, ëª¨ë¸, íŒŒì„œ ë“±)ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì—°ê²°í•˜ì—¬ í•˜ë‚˜ì˜ ì‹¤í–‰ íë¦„ì„ ë§Œë“œëŠ” êµ¬ì¡°ì„
- ë‹¨ì¼ ì§ˆì˜ì— ëŒ€í•œ ë‹¨ìˆœ ì‘ë‹µì„ ë„˜ì–´, ì—¬ëŸ¬ ë‹¨ê³„ì˜ ì²˜ë¦¬ ê³¼ì •ì„ ë¬¶ì–´ ìë™í™”ëœ ì‘ì—… íë¦„ì„ êµ¬ì„±í•  ìˆ˜ ìˆìŒ
- ì²´ì¸ì„ ì‚¬ìš©í•˜ë©´ í”„ë¡¬í”„íŠ¸ ë°˜ë³µ êµ¬ì„±, ëª¨ë¸ ì‘ë‹µ í›„ì²˜ë¦¬, ê²°ê³¼ í¬ë§¤íŒ… ë“±ì˜ ì‘ì—…ì„ ëª¨ë“ˆí™”í•˜ì—¬ ì¬ì‚¬ìš©ì„±ê³¼ ìœ ì§€ë³´ìˆ˜ì„±ì„ ë†’ì¼ ìˆ˜ ìˆìŒ

---

## 1. LCEL (LangChain Expression Language)

- LCELì€ LangChain ì»´í¬ë„ŒíŠ¸ë¥¼ `|` ì—°ì‚°ìë¡œ ì—°ê²°í•˜ì—¬ ì„ ì–¸ì ìœ¼ë¡œ ì²´ì¸ì„ êµ¬ì„±í•˜ëŠ” ë°©ì‹ì„
- ì»´í¬ë„ŒíŠ¸ëŠ” ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰ë˜ë©°, ì´ì „ ì¶œë ¥ì´ ë‹¤ìŒ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬ë¨  
- ì •ì˜ëœ ì²´ì¸ì€ í•˜ë‚˜ì˜ `Runnable`ë¡œ ê°„ì£¼ë˜ì–´, ë‹¤ë¥¸ ì²´ì¸ êµ¬ì„± ì‹œ ì¬ì‚¬ìš© ê°€ëŠ¥í•¨  
- ë°°ì¹˜ ì‹¤í–‰ ì‹œ ë‚´ë¶€ ìµœì í™”ë¥¼ í†µí•´ ë¦¬ì†ŒìŠ¤ë¥¼ ì ˆì•½í•˜ê³  ì²˜ë¦¬ ì†ë„ë¥¼ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŒ  
- LCELì€ í…ŒìŠ¤íŠ¸, ì‹¤í—˜, ë³µì¡í•œ íë¦„ ì œì–´ ë“± ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ êµ¬ì¡°í™”ëœ ì²´ì¸ì„ ë¹ ë¥´ê²Œ êµ¬ì„±í•  ìˆ˜ ìˆëŠ” íš¨ìœ¨ì ì¸ í‘œí˜„ ë°©ì‹ì„

---

## 2. Runnable í´ë˜ìŠ¤

- LangChainì˜ ëª¨ë“  ì»´í¬ë„ŒíŠ¸ëŠ” `Runnable` ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬í˜„í•˜ì—¬ ì¼ê´€ëœ ë°©ì‹ìœ¼ë¡œ ì‹¤í–‰ë¨  
- ì‹¤í–‰ ë©”ì„œë“œë¡œëŠ” `invoke` (ë‹¨ì¼ ì…ë ¥), `batch` (ì—¬ëŸ¬ ì…ë ¥), `stream` (ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬) ë“±ì„ ì§€ì›í•˜ë©°, ë™ê¸°/ë¹„ë™ê¸° ì²˜ë¦¬ ë°©ì‹ì— ë”°ë¼ ë‹¤ì–‘í•˜ê²Œ í™œìš© ê°€ëŠ¥  
- ëª¨ë“  `Runnable` ì»´í¬ë„ŒíŠ¸ëŠ” `|` ì—°ì‚°ìë¥¼ ì‚¬ìš©í•´ ì—°ê²°í•  ìˆ˜ ìˆìœ¼ë©°, ì´ë¥¼ í†µí•´ ì¬ì‚¬ìš©ì„±ê³¼ ì¡°í•©ì„±ì´ ë†’ì€ ì²´ì¸ì„ êµ¬ì„±í•  ìˆ˜ ìˆìŒ

**RunnableSequence**
- ì—¬ëŸ¬ `Runnable`ì„ ìˆœì°¨ì ìœ¼ë¡œ ì—°ê²°í•˜ì—¬ ì‹¤í–‰í•¨
- LCELë¡œ ì—°ê²°í•œ ì²´ì¸ì€ ë‚´ë¶€ì ìœ¼ë¡œ `RunnableSequence`ë¡œ ì»´íŒŒì¼ë¨
- ì¼ë°˜ì ìœ¼ë¡œëŠ” LCEL ë¬¸ë²•ì„ í™œìš©í•˜ì—¬ ì„ ì–¸ì ìœ¼ë¡œ êµ¬í˜„í•˜ëŠ” ë°©ì‹ì„ ì„ í˜¸í•¨

**RunnableParallel**
- ì—¬ëŸ¬ `Runnable` ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ êµ¬ì„±í•˜ì—¬ ë³‘ë ¬ì²˜ë¦¬ ê°€ëŠ¥í•¨
- ë™ì¼í•œ ì…ë ¥ê°’ì´ ê° `Runnable`ì— ì „ë‹¬ë˜ë©°, ê²°ê³¼ëŠ” í‚¤-ê°’ í˜•íƒœë¡œ ë°˜í™˜ë¨
- ì£¼ë¡œ ë°ì´í„° ì „ì²˜ë¦¬, ë³€í™˜, í¬ë§· ì¡°ì • ë“±ì— í™œìš©ë˜ë©°, ë‹¤ìŒ íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ì—ì„œ ìš”êµ¬í•˜ëŠ” ì¶œë ¥ í˜•ì‹ìœ¼ë¡œ ì¡°ì • ê°€ëŠ¥í•¨

**RunnableLambda**
- ì‚¬ìš©ì ì •ì˜ íŒŒì´ì¬ í•¨ìˆ˜ë¥¼ `Runnable` ê°ì²´ë¡œ ê°ì‹¸ëŠ” ë˜í¼ ì»´í¬ë„ŒíŠ¸ì„
- ì²´ì¸ ë‚´ì— ì‚¬ìš©ì ì •ì˜ ë¡œì§ì„ ì†ì‰½ê²Œ í†µí•©í•  ìˆ˜ ìˆì–´ ë°ì´í„° ì „ì²˜ë¦¬Â·í›„ì²˜ë¦¬ ë° ì¡°ê±´ë¶€ ë¶„ê¸° ì²˜ë¦¬ ë“±ì— ìœ ìš©í•¨
- ë‹¤ë¥¸ `Runnable` ê°ì²´ë“¤ê³¼ ê²°í•©í•˜ì—¬ ìœ ì—°í•˜ê³  ë³µì¡í•œ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ êµ¬ì„±ì´ ê°€ëŠ¥í•¨

**RunnablePassthrough**
- ì…ë ¥ê°’ì„ ë³€í˜• ì—†ì´ ê·¸ëŒ€ë¡œ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì „ë‹¬í•¨
- `RunnablePassthrough`ì€ ì…ë ¥ ë°ì´í„°ë¥¼ ìƒˆë¡œìš´ í‚¤ë¡œ ë§¤í•‘í•  ìˆ˜ ìˆì–´ ë³µìˆ˜ ì…ë ¥ì´ í•„ìš”í•œ ì²´ì¸ êµ¬ì„± ì‹œ ìœ ìš©í•˜ê²Œ í™œìš© ê°€ëŠ¥í•¨
- ì¤‘ê°„ì— ê°€ê³µì´ ì—†ëŠ” íˆ¬ëª…í•œ ë°ì´í„° íë¦„ì„ ì œê³µí•˜ë¯€ë¡œ íŒŒì´í”„ë¼ì¸ ë””ë²„ê¹…ì´ ìš©ì´í•¨

> âš ï¸ ìì„¸í•œ êµ¬í˜„ ë°©ë²•ì€ [ì˜ˆì œ] ì„¹ì…˜ì„ í†µí•´ í™•ì¸í•  ìˆ˜ ìˆìŒ

---

## 3. OutputParser í´ë˜ìŠ¤

- `OutputParser`ëŠ” LLM ì‘ë‹µì„ ì›í•˜ëŠ” ë°ì´í„° í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë° ì‚¬ìš©í•˜ëŠ” êµ¬ì„± ìš”ì†Œì„
- ë¬¸ìì—´, JSON, XML ë“± ì—¬ëŸ¬ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ íŒŒì‹±í•  ìˆ˜ ìˆìŒ
- íŒŒì‹±ëœ ì¶œë ¥ì€ ë‹¤ë¥¸ ì‹œìŠ¤í…œì´ë‚˜ í”„ë¡œì„¸ìŠ¤ì™€ ì—°ë™í•˜ëŠ” ë° ìœ ìš©í•¨

### 1\) StrOutputParser

### 2\) JSONOutputParser

- `JSONOutputParser`ëŠ” LLMì˜ ì‘ë‹µì„ ì—„ê²©í•œ JSON í˜•ì‹ìœ¼ë¡œ íŒŒì‹±í•˜ëŠ” ë° ì‚¬ìš©ë¨
- ì¶œë ¥ê°’ì˜ ë°ì´í„° ìœ íš¨ì„± ê²€ì¦ ë° ì¼ê´€ëœ ìŠ¤í‚¤ë§ˆ ë³´ì¥ì— ìœ ë¦¬í•¨
- ì¼ë°˜ì ìœ¼ë¡œ LLMì´ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ë„ë¡ `PromptTemplate`ì— ëª…ì‹œí•œ ë’¤, í•´ë‹¹ íŒŒì„œë¥¼ í†µí•´ ê²°ê³¼ë¥¼ êµ¬ì¡°í™”í•¨
- ì¶œë ¥ê°’ì„ ë°”ë¡œ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë³€í™˜í•´ ì‚¬ìš©í•  ìˆ˜ ìˆì–´, API ì‘ë‹µì´ë‚˜ ë‹¤ë¥¸ ì‹œìŠ¤í…œê³¼ ì—°ë™ ì‹œ ìœ ìš©í•¨

### 3\)  XMLOutputParser

- `XMLOutputParser`ëŠ” LLMì˜ ì‘ë‹µì„ ê³„ì¸µì  êµ¬ì¡°ë¥¼ ê°–ëŠ” XML í˜•ì‹ìœ¼ë¡œ íŒŒì‹±í•¨
- XMLì€ ë…¸ë“œ ê°„ì˜ ê´€ê³„ í‘œí˜„ì´ ê°€ëŠ¥í•˜ì—¬, ë³µì¡í•œ ë°ì´í„° êµ¬ì¡°ë‚˜ ë¬¸ì„œí˜• ì‘ë‹µì„ í‘œí˜„í•  ë•Œ íš¨ê³¼ì ì„
- ì¼ë°˜ì ì¸ JSON ë³´ë‹¤ ë¬¸ì„œ ì¤‘ì‹¬ì˜ êµ¬ì¡°ë‚˜ ë©”íƒ€ë°ì´í„°ê°€ ë§ì€ ì‘ë‹µì„ ë‹¤ë£° ë•Œ ìœ ë¦¬í•¨
- ë‚´ë¶€ì ìœ¼ë¡œ XML íŒŒì‹±ì„ ìœ„í•´ `defusedxml` íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ, ì‚¬ì „ ì„¤ì¹˜ê°€ í•„ìš”í•¨
- JSONì— ë¹„í•´ ì‚¬ìš© ë¹ˆë„ëŠ” ë‚®ì§€ë§Œ, RDF, ë¬¸ì„œ í¬ë§·, ì¼ë¶€ ì‚°ì—…ìš© ìŠ¤í‚¤ë§ˆì™€ ì—°ê³„ ì‹œ ìœ ìš©í•˜ê²Œ ì‚¬ìš©ë¨


---

## [ì˜ˆì œ] ì—¬í–‰ ì¼ì • ë„ìš°ë¯¸ ë§Œë“¤ê¸°

> ğŸ’¡ **Tip**
> - í•˜ë‚˜ì˜ Runnable, í”„ë¡¬í”„íŠ¸, í•¨ìˆ˜ëŠ” ë˜ë„ë¡ í•˜ë‚˜ì˜ ëª…í™•í•œ ê¸°ëŠ¥ë§Œ ìˆ˜í–‰í•˜ë„ë¡ êµ¬ì„±í•˜ëŠ” ê²ƒì´ ì¢‹ìŒ
> - ë³µì¡í•œ ë¡œì§ì„ ì—¬ëŸ¬ ë‹¨ê³„ë¡œ ë‚˜ëˆ„ì–´ êµ¬ì„±í•˜ë©´ ê°€ë…ì„±ê³¼ ìœ ì§€ë³´ìˆ˜ì„±ì´ í¬ê²Œ í–¥ìƒë¨

- ì‚¬ìš©ìì˜ ììœ ë¡œìš´ ì—¬í–‰ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•´ êµ¬ì¡°í™”ëœ ì •ë³´ë¡œ ë³€í™˜í•¨
- ìš”ì•½ëœ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹¤ì œ ì—¬í–‰ ì¼ì • í…Œì´ë¸”ì„ ìƒì„±í•¨

**1. Prompt**

```python
from langchain_core.prompts import ChatPromptTemplate

summarize_templete = """
{text}

ìœ„ì— ì…ë ¥ëœ í…ìŠ¤íŠ¸ë¥¼ ë‹¤ìŒ í•­ëª©ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”: 
- ì—¬í–‰ ì¼ì • :
- êµí†µí¸ ì¼ì • :
- ì—¬í–‰ ì¥ì†Œ :
- ì—¬í–‰ ìŠ¤íƒ€ì¼ :
- ì˜ˆì‚° :
- ì¶”ì²œ ìˆ™ì†Œ :"""

summarize_prompt = ChatPromptTemplate.from_messages([
    ("system", "ë‹¹ì‹ ì€ ì—¬í–‰ ì¼ì • ì‘ì„±ì„ ë„ì™€ì£¼ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."),
    ("human", summarize_templete)
])

planner_prompt = ChatPromptTemplate.from_template("""
ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ì—¬í–‰ ì¼ì •ì„ ê¸°ë°˜ìœ¼ë¡œ ì„¸ë¶€ ì—¬í–‰ ì¼ì •ì„ ì§œì£¼ì„¸ìš”.
í…ìŠ¤íŠ¸: {summary}
ê·œì¹™:
1. ë‚ ì§œ ë° ì‹œê°„ê³¼ ì¥ì†Œ, ì„¸ë¶€ ê³„íš í•­ëª©ìœ¼ë¡œ í‘œ í˜•íƒœë¡œ ì‘ì„±í•˜ì„¸ìš”.
2. ì—¬í–‰ ìŠ¤íƒ€ì¼ê³¼ ì¶”ì²œ ìˆ™ì†Œ, ì˜ˆì‚°ì— ë§ì¶”ì–´ ë™ì„ ì„ ê³ ë ¤í•˜ì—¬ ì¥ì†Œë¥¼ ì¶”ì²œí•˜ì„¸ìš”.
ë‹µë³€:""")
```

**2. Chain**

```python
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableParallel, RunnableLambda, RunnablePassthrough
from IPython.display import display, Markdown

model = ChatOpenAI(
    model="gpt-4.1-mini",
    temperature=0.4,
    top_p=0.7
)

# ì²´ì¸ êµ¬ì„±
summarize_chain = summarize_prompt | model | StrOutputParser()
planner_chain = planner_prompt | model | StrOutputParser()

# ìµœì¢… ì²´ì¸
chain = (
    summarize_chain |
    RunnableParallel(
        summary=RunnablePassthrough(),
        plan=lambda x: planner_chain.invoke({"summary": x})
    ) |
    RunnableLambda(lambda x: f"<ìš”ì•½>\n{x['summary']}\n\n<ì¼ì •>\n{x['plan']}")
)

# ì²´ì¸ ì‹¤í–‰
text = """ë‚´ì¼ ì˜¤ì „ 8ì‹œì— ì„œìš¸ì—­ì—ì„œ ì¶œë°œí•´ì„œ ì˜¤ì „ 11ì‹œì— ë¶€ì‚°ì—­ì— ë„ì°©í•´.
2ë°• 3ì¼ë™ì•ˆ ë¶€ì‚° ê¸°ì¥êµ° ë¶€ê·¼ì—ì„œ ì—¬í–‰í•˜ê³  ì‹¶ì–´.
ë§›ìˆëŠ” ê±° ë¨¹ìœ¼ë©´ì„œ ëŒì•„ë‹¤ë‹ˆê³  ì‹¶ê³ , ëª…ì†Œë„ ê°€ê³  ì‹¶ì–´.
ê·¸ëŸ°ë° ìë™ì°¨ê°€ ì—†ì–´ì„œ ê±¸ì–´ë‹¤ë‹ˆê±°ë‚˜ ëŒ€ì¤‘êµí†µì„ ì´ìš©í•´ì•¼í•´.
ê·¸ë¦¬ê³  ì—¬í–‰ ë§ˆì§€ë§‰ ë‚ ì€ ì˜¤í›„ 5ì‹œì— ë¶€ì‚°ì—­ì—ì„œ ì¶œë°œí•´.
ì—¬ë™ìƒì´ë‘ ë‘˜ì´ì„œ ê°€ë ¤ê³  í•˜ê³ , ì˜ˆì‚°ì€ 50ë§Œì› ë‚´ì™¸ë¡œ ë¶€íƒí•´."""
result = chain.invoke({"text": text})
display(Markdown(result))
```

---

## 4. ì‚¬ìš©ì ì •ì˜ Output Parser

- ê¸°ë³¸ `OutputParser`ë¡œ ì²˜ë¦¬í•˜ê¸° ì–´ë ¤ìš´ ë³µì¡í•œ ì¶œë ¥ í˜•ì‹ì´ë‚˜ ë„ë©”ì¸ íŠ¹í™”ëœ ìš”êµ¬ì‚¬í•­ì— ëŒ€ì‘í•˜ê¸° ìœ„í•´, ì‚¬ìš©ì ì •ì˜ íŒŒì„œë¥¼ ì§ì ‘ êµ¬í˜„í•  ìˆ˜ ìˆìŒ


```python
from langchain.chat_models import init_chat_model

llm = init_chat_model("gpt-4.1-mini", model_provider="openai")
```


```python
from langchain_core.prompts import PromptTemplate

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
step_prompt = PromptTemplate(
    template="""ë‹¤ìŒ í…ìŠ¤íŠ¸ì— ëŒ€í•´ì„œ ì‘ì—…ì„ ìˆœì„œëŒ€ë¡œ ìˆ˜í–‰í•˜ì„¸ìš”:

    [í…ìŠ¤íŠ¸]
    {text}

    [ì‘ì—… ìˆœì„œ]
    1. í…ìŠ¤íŠ¸ë¥¼ 1ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½
    2. í•µì‹¬ í‚¤ì›Œë“œ 3ê°œ ì¶”ì¶œ
    3. ê°ì • ë¶„ì„ ìˆ˜í–‰(ê¸ì •/ë¶€ì •/ì¤‘ë¦½)

    [ì‘ì—… ê²°ê³¼]
    """,
    input_variables=["text"]
)

# ì…ë ¥ í…ìŠ¤íŠ¸
text = """
ì–‘ì ì»´í“¨íŒ…ì€ ì–‘ìì—­í•™ì˜ ì›ë¦¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ìƒˆë¡œìš´ í˜•íƒœì˜ ê³„ì‚° ë°©ì‹ì´ë‹¤.
ê¸°ì¡´ì˜ ê³ ì „ì  ì»´í“¨í„°ëŠ” 0ê³¼ 1ë¡œ ì´ë£¨ì–´ì§„ ì´ì§„ë²•(bit)ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ì§€ë§Œ,
ì–‘ì ì»´í“¨í„°ëŠ” ì–‘ì ë¹„íŠ¸(íë¹„íŠ¸, qubit)ë¥¼ ì‚¬ìš©í•˜ì—¬ í›¨ì”¬ ë” ë³µì¡í•˜ê³  ë¹ ë¥¸ ê³„ì‚°ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.

íë¹„íŠ¸ëŠ” ë™ì‹œì— 0ê³¼ 1ì˜ ìƒíƒœë¥¼ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ì–‘ì ì¤‘ì²©(superposition) ìƒíƒœë¥¼ í™œìš©í•˜ë©°,
ì´ë¥¼ í†µí•´ ë³‘ë ¬ ê³„ì‚°ê³¼ ê°™ì€ ê³ ê¸‰ ê¸°ëŠ¥ì´ ê°€ëŠ¥í•˜ë‹¤.
"""
```

### 1\) RunnableLambda ê¸°ë°˜ ë°©ì‹

- LLM ì‘ë‹µì—ì„œ íŠ¹ì • í‚¤ì›Œë“œë¥¼ ì¶”ì¶œ, ì¡°ê±´ ë¶„ê¸° ì²˜ë¦¬, ì™¸ë¶€ í•¨ìˆ˜ í˜¸ì¶œ ë“± ê³ ìœ í•œ í›„ì²˜ë¦¬ ë¡œì§ì„ ì‚½ì…í•  ìˆ˜ ìˆìŒ
- ê³ ì •ëœ ë°ì´í„° êµ¬ì¡° ì´ì™¸ì˜ ìœ ì—°í•œ í˜•ì‹ì„ ë‹¤ë£¨ê±°ë‚˜, ëª¨ë¸ ì¶œë ¥ì˜ í›„ì²˜ë¦¬ë¥¼ ì½”ë“œ ê¸°ë°˜ìœ¼ë¡œ ìƒì„¸íˆ ì¡°ì ˆí•  ë•Œ ìœ ìš©í•¨


```python
from langchain_core.messages import AIMessage
from langchain_core.runnables import RunnableLambda
from typing import Dict

# ì‚¬ìš©ì ì •ì˜ íŒŒì„œ
def custom_parser(ai_message: AIMessage) -> Dict:
    """ëª¨ë¸ ì¶œë ¥ì„ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë³€í™˜"""
    return ai_message.content.split('\n')

# ì‹¤í–‰
chain = step_prompt | llm | RunnableLambda(custom_parser)
result = chain.invoke({"text": text})

# ê²°ê³¼ ì¶œë ¥
pprint(result)
```

    ['1. ìš”ì•½: ì–‘ì ì»´í“¨íŒ…ì€ ì–‘ìì—­í•™ì˜ ì›ë¦¬ë¥¼ ì´ìš©í•´ íë¹„íŠ¸ë¥¼ í†µí•œ ì¤‘ì²© ìƒíƒœë¡œ ê¸°ì¡´ ì»´í“¨í„°ë³´ë‹¤ í›¨ì”¬ ë¹ ë¥´ê³  ë³µì¡í•œ ê³„ì‚°ì„ ìˆ˜í–‰í•˜ëŠ” ìƒˆë¡œìš´ '
     'ê³„ì‚° ë°©ì‹ì´ë‹¤.  ',
     '2. í•µì‹¬ í‚¤ì›Œë“œ: ì–‘ì ì»´í“¨íŒ…, íë¹„íŠ¸, ì¤‘ì²©(superposition)  ',
     '3. ê°ì • ë¶„ì„: ì¤‘ë¦½']
    

### 2\) typing ê¸°ë°˜ ë°©ì‹

- ì¶œë ¥ êµ¬ì¡°ë¥¼ ê°€ë³ê²Œ ëª…ì‹œí•˜ë©´ì„œ, ê°„ë‹¨ JSON ì‘ë‹µì„ ê¸°ëŒ€í•  ë•Œ ì‚¬ìš©í•¨


```python
from typing import TypedDict, Annotated 

# êµ¬ì¡°í™”ëœ ì¶œë ¥ ìŠ¤í‚¤ë§ˆ
class AnalysisResult(TypedDict):
    """ë¶„ì„ ê²°ê³¼ ìŠ¤í‚¤ë§ˆ"""
    summary: Annotated[str, ..., "í•µì‹¬ ìš”ì•½"]   # ...ì€ í•„ìˆ˜ ì…ë ¥ì„ ì˜ë¯¸
    keywords: Annotated[list[str], ..., "ì£¼ìš” í‚¤ì›Œë“œ"]
    sentiment: Annotated[str, ..., "ê¸ì •/ë¶€ì •/ì¤‘ë¦½"]

structured_llm = llm.with_structured_output(AnalysisResult)

# ì‹¤í–‰
chain = step_prompt | structured_llm
output = chain.invoke({"text": text})
pprint(output)
```

    {'keywords': ['ì–‘ì ì»´í“¨íŒ…', 'íë¹„íŠ¸', 'ì–‘ì ì¤‘ì²©'],
     'sentiment': 'ì¤‘ë¦½',
     'summary': 'ì–‘ì ì»´í“¨íŒ…ì€ ì–‘ìì—­í•™ ì›ë¦¬ë¥¼ ì´ìš©í•´ íë¹„íŠ¸ë¥¼ í†µí•´ ê³ ì „ ì»´í“¨í„°ë³´ë‹¤ í›¨ì”¬ ë¹ ë¥´ê³  ë³µì¡í•œ ê³„ì‚°ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ìƒˆë¡œìš´ '
                'ê³„ì‚° ë°©ì‹ì´ë‹¤.'}
    

### 3\) pydantic ê¸°ë°˜ ë°©ì‹

- ë°ì´í„° íƒ€ì… ê²€ì¦, í•„ìˆ˜ í•­ëª© ê²€ì‚¬, ìƒì„¸ ì˜¤ë¥˜ ì²˜ë¦¬ê¹Œì§€ ê°€ëŠ¥í•œ ê²¬ê³ í•œ ë°©ì‹ì„
- êµ¬ì¡°ê°€ ëª…í™•í•œ ì‘ë‹µì„ ê¸°ëŒ€í•  ìˆ˜ ìˆì–´, API ì‘ë‹µ ì²˜ë¦¬, DB ì €ì¥, UI ë Œë”ë§ ë“±ê³¼ì˜ ì—°ë™ì— íš¨ê³¼ì ì„


```python
from typing import List, Literal
from pydantic import BaseModel, Field

# êµ¬ì¡°í™”ëœ ì¶œë ¥ ìŠ¤í‚¤ë§ˆ
class AnalysisResult(BaseModel):
    """ë¶„ì„ ê²°ê³¼ ìŠ¤í‚¤ë§ˆ"""
    summary: str = Field(...,  description="í…ìŠ¤íŠ¸ì˜ í•µì‹¬ ë‚´ìš© ìš”ì•½")
    keywords: List[str] = Field(..., description="í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œí•œ ì£¼ìš” í‚¤ì›Œë“œ")
    sentiment: Literal["ê¸ì •", "ë¶€ì •", "ì¤‘ë¦½"] = Field(
        ..., 
        description="í…ìŠ¤íŠ¸ì˜ ì „ë°˜ì ì¸ ê°ì • ë¶„ì„ ê²°ê³¼"
    )

structured_llm = llm.with_structured_output(AnalysisResult)

# ì‹¤í–‰
chain = step_prompt | structured_llm
output = chain.invoke({"text": text})
print(output.summary)
print(output.keywords)
print(output.sentiment)
```

    ì–‘ì ì»´í“¨íŒ…ì€ ì–‘ì ì¤‘ì²© ìƒíƒœë¥¼ í™œìš©í•˜ëŠ” íë¹„íŠ¸ë¥¼ í†µí•´ ê¸°ì¡´ ê³ ì „ ì»´í“¨í„°ë³´ë‹¤ ë” ë³µì¡í•˜ê³  ë¹ ë¥¸ ê³„ì‚°ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ìƒˆë¡œìš´ ê³„ì‚° ë°©ì‹ì´ë‹¤.
    ['ì–‘ì ì»´í“¨íŒ…', 'íë¹„íŠ¸', 'ì–‘ì ì¤‘ì²©']
    ê¸ì •
    
---

## [ì˜ˆì œ] í•™ìŠµ ë„ìš°ë¯¸ ë§Œë“¤ê¸°

***í™˜ê²½ ì„¤ì •***


```python
from dotenv import load_dotenv
load_dotenv()
```

### 1\) í€´ì¦ˆ ìƒì„± ì±—ë´‡


```python
from typing import List
from pydantic import BaseModel, Field
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI

# ìŠ¤í‚¤ë§ˆ ì •ì˜ì˜
class QuizQuestion(BaseModel):
    """í€´ì¦ˆ ìŠ¤í‚¤ë§ˆ"""
    question: str = Field(..., description="í€´ì¦ˆ ë¬¸ì œ")
    options: List[str] = Field(..., description="ë³´ê¸° (4ê°œ)")
    correct_answer: int = Field(..., description="ì •ë‹µ ë²ˆí˜¸ (1-4)")
    explanation: str = Field(..., description="ì •ë‹µ ì„¤ëª…")


# í”„ë¡¬í”„íŠ¸ íƒ¬í”Œë¦¿
quiz_prompt = PromptTemplate(
    template="""ë‹¤ìŒ ì£¼ì œì— ëŒ€í•œ í€´ì¦ˆ ë¬¸ì œë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”:
    
ì£¼ì œ: {topic}
ë‚œì´ë„(ìƒ/ì¤‘/í•˜): {difficulty}

ë‹¤ìŒ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” í€´ì¦ˆë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:
1. ë¬¸ì œëŠ” ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ
2. 4ê°œì˜ ë³´ê¸° ì œê³µ
3. ì •ë‹µê³¼ ì˜¤ë‹µì€ ë¹„ìŠ·í•œ ìˆ˜ì¤€ìœ¼ë¡œ
4. ìƒì„¸í•œ ì •ë‹µ ì„¤ëª… í¬í•¨""",
    input_variables=["topic", "difficulty"]
)

llm = ChatOpenAI(model="gpt-4.1-mini", temperature=0.3)

# êµ¬ì¡°í™”ëœ Outupt Parser ì„¤ì •
structured_llm = llm.with_structured_output(QuizQuestion)

# ì‹¤í–‰
chain = quiz_prompt | structured_llm
output = chain.invoke({"topic": "LangChain", "difficulty": "ìƒ"})

# ê²°ê³¼ ì¶œë ¥
pprint(f"í€´ì¦ˆ ë¬¸ì œ: {output.question}")
pprint(f"ë³´ê¸°: {output.options}")
pprint(f"ì •ë‹µ: {output.correct_answer}")
pprint(f"ì •ë‹µ ì„¤ëª…: {output.explanation}")
```

    "í€´ì¦ˆ ë¬¸ì œ: LangChainì—ì„œ 'ì²´ì¸(chain)'ì˜ ì£¼ìš” ì—­í• ì€ ë¬´ì—‡ì¸ê°€?"
    ("ë³´ê¸°: ['ì—¬ëŸ¬ ê°œì˜ LLM í˜¸ì¶œì„ ìˆœì°¨ì ìœ¼ë¡œ ì—°ê²°í•˜ì—¬ ë³µì¡í•œ ì‘ì—…ì„ ìˆ˜í–‰í•œë‹¤.', 'ë°ì´í„°ë² ì´ìŠ¤ì™€ì˜ ì—°ê²°ì„ ê´€ë¦¬í•œë‹¤.', 'ì‚¬ìš©ì "
     "ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬ì„±í•˜ëŠ” ëª¨ë“ˆì´ë‹¤.', 'ëª¨ë¸ í•™ìŠµì„ ìœ„í•œ ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ë‹´ë‹¹í•œë‹¤.']")
    'ì •ë‹µ: 1'
    ("ì •ë‹µ ì„¤ëª…: LangChainì—ì„œ 'ì²´ì¸'ì€ ì—¬ëŸ¬ ê°œì˜ ì–¸ì–´ ëª¨ë¸ í˜¸ì¶œì„ ìˆœì°¨ì ìœ¼ë¡œ ì—°ê²°í•˜ì—¬ ë³µì¡í•œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. ì´ë¥¼ "
     'í†µí•´ ë‹¨ì¼ ëª¨ë¸ í˜¸ì¶œë¡œëŠ” ì–´ë ¤ìš´ ë³µí•©ì ì¸ ì‘ì—…ì„ ë‹¨ê³„ë³„ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì´ë‚˜ UI êµ¬ì„±, ë°ì´í„° ì „ì²˜ë¦¬ëŠ” ê°ê° '
     'ë‹¤ë¥¸ ì»´í¬ë„ŒíŠ¸ê°€ ë‹´ë‹¹í•©ë‹ˆë‹¤.')
    

### 2\) ê°œë… ì„¤ëª… ì±—ë´‡


```python
from typing import List
from pydantic import BaseModel, Field
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI

# ìŠ¤í‚¤ë§ˆ ì •ì˜ì˜
class ConceptExplanation(BaseModel):
    """ê°œë… ì„¤ëª… ìŠ¤í‚¤ë§ˆ"""
    topic: str = Field(..., description="ì£¼ì œ")
    explanation: str = Field(..., description="ê°œë… ì„¤ëª…")
    examples: str = Field(..., description="ì‚¬ìš© ì˜ˆì‹œ")
    related_concepts: List[str] = Field(..., description="ê´€ë ¨ëœ ê°œë… (4ê°œ)")

# í”„ë¡¬í”„íŠ¸ íƒ¬í”Œë¦¿
concept_prompt = PromptTemplate(
    template="""ë‹¤ìŒ ì£¼ì œì— ëŒ€í•´ ì°¨ê·¼ì°¨ê·¼ ì„¤ëª…í•´ ì£¼ì„¸ìš”:
    
ì£¼ì œ: {topic}
ë‚œì´ë„(ìƒ/ì¤‘/í•˜): {difficulty}

ë‹¤ìŒì„ ì°¨ë¡€ëŒ€ë¡œ ì‘ì„±í•˜ì„¸ìš”:
1. ì£¼ì œì— ëŒ€í•œ ê°œë… ì„¤ëª…
2. ì£¼ì œì— ëŒ€í•œ ì‚¬ìš© ì˜ˆì‹œ
3. ê´€ë ¨ ê°œë… ëª©ë¡ (4ê°œ)
""",
    input_variables=["topic", "difficulty"]
)

llm = ChatOpenAI(model="gpt-4.1-mini", temperature=0.3)

# êµ¬ì¡°í™”ëœ Outupt Parser ì„¤ì •
structured_llm = llm.with_structured_output(ConceptExplanation)

# ì‹¤í–‰
chain = quiz_prompt | structured_llm
output = chain.invoke({"topic": "LangChain", "difficulty": "í•˜"})

# ê²°ê³¼ ì¶œë ¥
pprint(f"ì£¼ì œ: {output.topic}")
pprint(f"ì„¤ëª…: {output.explanation}")
pprint(f"ì˜ˆì‹œ: {output.examples}")
pprint(f"ê´€ë ¨ ê°œë…: {output.related_concepts}")
```

    'ì£¼ì œ: LangChain'
    ('ì„¤ëª…: LangChainì€ ì–¸ì–´ ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ë‹¤ì–‘í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°œë°œí•  ìˆ˜ ìˆë„ë¡ ë•ëŠ” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ì£¼ë¡œ ìì—°ì–´ ì²˜ë¦¬ ì‘ì—…ì„ '
     'ì‰½ê²Œ ì—°ê²°í•˜ê³  í™•ì¥í•  ìˆ˜ ìˆê²Œ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.')
    'ì˜ˆì‹œ: ì˜ˆë¥¼ ë“¤ì–´, LangChainì„ ì‚¬ìš©í•˜ë©´ í…ìŠ¤íŠ¸ ìš”ì•½, ì§ˆë¬¸ ì‘ë‹µ, ëŒ€í™”í˜• ì—ì´ì „íŠ¸ ë“±ì„ ì‰½ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.'
    "ê´€ë ¨ ê°œë…: ['ìì—°ì–´ ì²˜ë¦¬', 'ì–¸ì–´ ëª¨ë¸', 'í”„ë ˆì„ì›Œí¬', 'AI ì• í”Œë¦¬ì¼€ì´ì…˜']"

---

## Reference

- LangChain ë¬¸ì„œ : ğŸ”— [Runnable](https://python.langchain.com/api_reference/core/runnables.html) / [OutputParser](https://python.langchain.com/api_reference/core/output_parsers.html)