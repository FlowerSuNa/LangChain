{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "151d7883",
   "metadata": {},
   "source": [
    "## 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c754de9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcabc05",
   "metadata": {},
   "source": [
    "# LangGraph 맛보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3358ec2c",
   "metadata": {},
   "source": [
    "## 1. 기본 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69be331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict, Literal\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# 1. 상태 정의\n",
    "class MyState(TypedDict):\n",
    "    name: str\n",
    "    is_morning: bool\n",
    "\n",
    "# 2. 노드 함수 정의\n",
    "def greet_user(state: MyState) -> MyState:\n",
    "    print(f\"Hi, {state['name']}!\")\n",
    "    return state\n",
    "\n",
    "def say_good_morning(state: MyState) -> MyState:\n",
    "    print(\"Good morning!\")\n",
    "    return state\n",
    "\n",
    "def say_hello(state: MyState) -> MyState:\n",
    "    print(\"Hello!\")\n",
    "    return state\n",
    "\n",
    "# 3. 조건 함수 정의\n",
    "def is_morning(state: MyState) -> Literal[\"morning\", \"not_morning\"]:\n",
    "    return \"morning\" if state[\"is_morning\"] else \"not_morning\"\n",
    "\n",
    "# 4. 그래프 구성\n",
    "builder = StateGraph(MyState)\n",
    "\n",
    "builder.add_node(\"greet_user\", greet_user)\n",
    "builder.add_node(\"say_good_morning\", say_good_morning)\n",
    "builder.add_node(\"say_hello\", say_hello)\n",
    "\n",
    "builder.add_edge(START, \"greet_user\")\n",
    "builder.add_conditional_edges(\n",
    "    \"greet_user\",\n",
    "    is_morning,\n",
    "    {\n",
    "        \"morning\": \"say_good_morning\",\n",
    "        \"not_morning\": \"say_hello\",\n",
    "    },\n",
    ")\n",
    "builder.add_edge(\"say_good_morning\", END)\n",
    "builder.add_edge(\"say_hello\", END)\n",
    "\n",
    "# 5. 그래프 컴파일\n",
    "graph = builder.compile()\n",
    "\n",
    "# 6. 그래프 시각화\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3be98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 실행\n",
    "graph.invoke({\"name\": \"Bob\", \"is_morning\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8b7c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 실행\n",
    "for step in graph.stream({\"name\": \"Bob\", \"is_morning\": False}, stream_mode=\"values\"):\n",
    "    print(step)\n",
    "    print(\"---\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed79c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 실행\n",
    "for step in graph.stream({\"name\": \"Bob\", \"is_morning\": False}, stream_mode=\"updates\"):\n",
    "    print(step)\n",
    "    print(\"---\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7054c0eb",
   "metadata": {},
   "source": [
    "## 2. 고급 기능 사용 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7fc3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Command\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, AnyMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from typing import TypedDict, Annotated\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# 시스템 프롬프트 정의\n",
    "SUMMARY_PROMPT = \"You are a helpful assistant that summarizes the following text.\"\n",
    "EVALUATE_PROMPT = \"You are a helpful assistant that evaluates the quality of a summary.\\n\" \\\n",
    "                  \"You must provide a quality score between 0.0 and 1.0, where 0.0 is the lowest quality and 1.0 is the highest quality.\"\n",
    "IMPROVE_PROMPT = \"You are a helpful assistant that enhances low-quality summaries generated by AI.\\n\" \\\n",
    "                 \"Your goal is to rewrite them to be clearer, more accurate, and more natural.\"\n",
    "\n",
    "# 출력 구조화\n",
    "class Summary(BaseModel):\n",
    "    summary: Annotated[str, Field(description=\"The summary of the text\")]\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    quality: Annotated[float, Field(description=\"The quality of the summary\", ge=0, le=1)]\n",
    "\n",
    "# 모델 정의\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "# 상태 정의\n",
    "class SummaryState(TypedDict):\n",
    "    text: str\n",
    "    summary: str\n",
    "    quality: float\n",
    "    finalized: bool\n",
    "    iteration: int\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "# 1. 요약 노드\n",
    "def summarize_text(state: SummaryState) -> Command:\n",
    "    messages = [\n",
    "        SystemMessage(content=SUMMARY_PROMPT),\n",
    "        HumanMessage(content=f\"Please summarize the following text: {state['text']}\\n\\nSummary:\")\n",
    "    ]\n",
    "    response = llm.with_structured_output(Summary).invoke(messages)\n",
    "\n",
    "    print(f\"[summarize_text] 요약 완료\")\n",
    "    return Command(\n",
    "        goto=\"evaluate_summary\",\n",
    "        update={\n",
    "            \"summary\": response.summary, \n",
    "            \"iteration\": 0,\n",
    "            \"messages\": messages + [AIMessage(content=response.summary)]\n",
    "        }\n",
    "    )\n",
    "\n",
    "# 2. 품질 평가 노드\n",
    "def evaluate_summary(state: SummaryState) -> Command:\n",
    "    messages = [\n",
    "        SystemMessage(content=EVALUATE_PROMPT),\n",
    "        HumanMessage(content=f\"The text is: {state['text']}\\n\\nPlease evaluate the following summary: {state['summary']}\")\n",
    "    ]\n",
    "    response = llm.with_structured_output(Evaluation).invoke(messages)\n",
    "\n",
    "    print(f\"[evaluate_summary] 평가 결과: {response.quality}\")\n",
    "\n",
    "    # 품질에 따라 다음 노드 분기 및 상태 업데이트\n",
    "    return Command(\n",
    "        goto=\"finalize_summary\" if response.quality > 0.8 or state[\"iteration\"] > 3 else \"improve_summary\",\n",
    "        update={\n",
    "            \"quality\": response.quality, \n",
    "            \"messages\": messages + [AIMessage(content=str(response.quality))]\n",
    "        }\n",
    "    )\n",
    "\n",
    "# 3. 개선 노드\n",
    "def improve_summary(state: SummaryState) -> Command:\n",
    "    messages = [\n",
    "        SystemMessage(content=IMPROVE_PROMPT),\n",
    "        HumanMessage(content=f\"The text is: {state['text']}\\n\\n\"\n",
    "                             f\"Please enhance the following summary: {state['summary']}\\n\\nEnhanced Summary:\")\n",
    "    ]\n",
    "    response = llm.with_structured_output(Summary).invoke(messages)\n",
    "\n",
    "    print(f\"[improve_summary] 요약 수정됨\")\n",
    "    return Command(\n",
    "        goto=\"evaluate_summary\",\n",
    "        update={\n",
    "            \"summary\": response.summary, \n",
    "            \"iteration\": state[\"iteration\"] + 1,\n",
    "            \"messages\": messages + [AIMessage(content=response.summary)]\n",
    "        }\n",
    "    )\n",
    "\n",
    "# 4. 최종화 노드\n",
    "def finalize_summary(state: SummaryState) -> Command:\n",
    "    print(f\"[finalize_summary] 최종 요약 완료\")\n",
    "    return Command(\n",
    "        goto=END,\n",
    "        update={\"finalized\": True}\n",
    "    )\n",
    "\n",
    "# 그래프 생성\n",
    "builder = StateGraph(SummaryState)\n",
    "\n",
    "builder.add_node(\"summarize_text\", summarize_text)\n",
    "builder.add_node(\"evaluate_summary\", evaluate_summary)\n",
    "builder.add_node(\"improve_summary\", improve_summary)\n",
    "builder.add_node(\"finalize_summary\", finalize_summary)\n",
    "\n",
    "builder.add_edge(START, \"summarize_text\")\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# 테스트 케이스\n",
    "text = \"\"\"\n",
    "The app is useful. I use it every day. Some features are hard to find. But I still use it. It’s okay.\n",
    "\"\"\"\n",
    "for step in graph.stream({\"text\": text}, stream_mode=\"updates\"):\n",
    "    print(step)\n",
    "    print(\"---\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9532424",
   "metadata": {},
   "source": [
    "## 3. Send 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cd1374",
   "metadata": {},
   "source": [
    "> Map-Reduce 패턴 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971f79f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Send\n",
    "from langchain_core.documents import Document\n",
    "from typing import TypedDict, List, Annotated\n",
    "from operator import add\n",
    "from IPython.display import Image, display\n",
    "from pprint import pprint\n",
    "\n",
    "# 전체 상태 정의\n",
    "class OverallState(TypedDict):\n",
    "    docs: List[Document]\n",
    "    summaries: Annotated[List[str], add]\n",
    "\n",
    "# 로컬 상태 정의\n",
    "class DocState(TypedDict):\n",
    "    doc: Document\n",
    "\n",
    "# 라우터 함수\n",
    "def map_router(state: OverallState) -> List[Send]:\n",
    "    return [Send(\"map_node\", {\"doc\": doc}) for doc in state[\"docs\"]]\n",
    "\n",
    "# 맵 노드 함수\n",
    "def map_node(state: DocState) -> OverallState:\n",
    "    doc = state[\"doc\"]\n",
    "    summary = f\"{doc.metadata['source']}: {doc.page_content[:30]}...\"\n",
    "    return {\"summaries\": [summary]}\n",
    "\n",
    "# 그래프 생성\n",
    "builder = StateGraph(OverallState)\n",
    "\n",
    "builder.add_node(\"map_node\", map_node)\n",
    "builder.add_conditional_edges(START, map_router, [\"map_node\"])\n",
    "builder.add_edge(\"map_node\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# 테스트\n",
    "docs = [\n",
    "    Document(page_content=\"LangChain is a framework for building LLM-powered apps.\", metadata={\"source\": \"intro\"}),\n",
    "    Document(page_content=\"StateGraph enables structured workflows with shared state.\", metadata={\"source\": \"graph\"}),\n",
    "    Document(page_content=\"Send can dynamically route data to other nodes.\", metadata={\"source\": \"send\"}),\n",
    "]\n",
    "result = graph.invoke({\"docs\": docs})\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1843e212",
   "metadata": {},
   "source": [
    "# ReAct Agent 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19c6082",
   "metadata": {},
   "source": [
    "## 1. Tool 바인딩 활용\n",
    "> `ToolNode`와 `Tool` 바인딩을 사용한 Reasoning + Acting 패턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7800fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from typing import Annotated, Sequence\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.tools.ddg_search import DuckDuckGoSearchRun\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.types import Send\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "# 검색 도구\n",
    "search_tool = DuckDuckGoSearchRun(name=\"search_tool\")\n",
    "\n",
    "# 날씨 도구\n",
    "@tool\n",
    "def weather_tool(latitude: float, longitude: float) -> str:\n",
    "    \"\"\"Get current weather information for a specific latitude/longitude.\n",
    "    \n",
    "    Args:\n",
    "        latitude: Latitude coordinate\n",
    "        longitude: Longitude coordinate\n",
    "        \n",
    "    Returns:\n",
    "        Weather information for the coordinates\n",
    "    \"\"\"\n",
    "    try:\n",
    "        url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "        params = {\n",
    "            \"latitude\": latitude,\n",
    "            \"longitude\": longitude,\n",
    "            \"current_weather\": \"true\",\n",
    "            \"hourly\": \"relative_humidity_2m\"\n",
    "        }\n",
    "        resp = requests.get(url, params=params, timeout=5)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "        # 기온\n",
    "        temp = data.get(\"current_weather\", {}).get(\"temperature\")\n",
    "        # 습도: 가장 가까운 시간의 습도 사용\n",
    "        humidity = \"N/A\"\n",
    "        if \"hourly\" in data and \"relative_humidity_2m\" in data[\"hourly\"]:\n",
    "            # 현재 시간 index 찾기\n",
    "            current_time = data[\"current_weather\"][\"time\"]\n",
    "            times = data[\"hourly\"][\"time\"]\n",
    "            humidities = data[\"hourly\"][\"relative_humidity_2m\"]\n",
    "            if current_time in times:\n",
    "                idx = times.index(current_time)\n",
    "                humidity = humidities[idx]\n",
    "            else:\n",
    "                humidity = humidities[0]\n",
    "        return f\"현재 기온: {temp}°C, 습도: {humidity}%\"\n",
    "    except Exception as e:\n",
    "        return f\"날씨 API 호출 오류: {str(e)}\"\n",
    "\n",
    "# LLM 정의\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# 도구 정의\n",
    "tools = [search_tool, weather_tool]\n",
    "\n",
    "# LLM에 도구 바인딩\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# 시스템 메시지 정의\n",
    "system_message = SystemMessage(content=\"\"\"You are a helpful AI assistant that can use tools to answer questions.\n",
    "\n",
    "Available tools:\n",
    "- search_tool: For searching information  \n",
    "- weather_tool: For weather information\n",
    "\n",
    "When you need to use a tool, think step by step:\n",
    "1. Identify what information you need\n",
    "2. Choose the appropriate tool\n",
    "3. Use the tool with the correct parameters\n",
    "4. Analyze the results\n",
    "5. Provide a helpful response\n",
    "\n",
    "If you can answer directly without tools, do so. Always be helpful and accurate.\"\"\")\n",
    "\n",
    "# 상태 정의\n",
    "class AgentState(MessagesState):\n",
    "    ...\n",
    "\n",
    "# 에이전트 노드\n",
    "def agent_node(state: AgentState) -> List[Send]:\n",
    "    messages = [system_message] + state[\"messages\"]\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    \n",
    "    print(f\"[Agent] 응답 생성: {response.content[:20]}...\")\n",
    "    if response.tool_calls:\n",
    "        print(f\"[Agent] 도구 호출: {[tool['name'] for tool in response.tool_calls]}\")\n",
    "\n",
    "        return [Send(\"tools\", {\n",
    "                \"tool_name\": tool_call[\"name\"], \n",
    "                \"parameters\": tool_call.get(\"parameters\", {})\n",
    "            }) for tool_call in response.tool_calls\n",
    "        ]\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# 그래프 구성\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# 노드 추가\n",
    "workflow.add_node(\"agent\", agent_node)      # 에이전트 노드\n",
    "workflow.add_node(\"tools\", ToolNode(tools)) # 도구 실행 노드\n",
    "\n",
    "# 엣지 설정\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    tools_condition,\n",
    "    {\n",
    "        \"tools\": \"tools\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# 그래프 컴파일\n",
    "react_agent = workflow.compile()\n",
    "\n",
    "# 그래프 시각화\n",
    "display(Image(react_agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0d25d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 테스트 예제들 ===\n",
    "\n",
    "# 테스트 1: 계산 질문\n",
    "def test_calculation():\n",
    "    print(\"=== 테스트 1: 계산 질문 ===\")\n",
    "    question = \"What is 25 * 4 + 18?\"\n",
    "    \n",
    "    result = react_agent.invoke({\n",
    "        \"messages\": [HumanMessage(content=question)]\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n질문: {question}\")\n",
    "    print(f\"최종 답변: {result['messages'][-1].content}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# 테스트 2: 검색 질문  \n",
    "def test_search():\n",
    "    print(\"=== 테스트 2: 검색 질문 ===\")\n",
    "    question = \"What is Python programming language?\"\n",
    "    \n",
    "    result = react_agent.invoke({\n",
    "        \"messages\": [HumanMessage(content=question)]\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n질문: {question}\")\n",
    "    print(f\"최종 답변: {result['messages'][-1].content}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# 테스트 3: 날씨 질문\n",
    "def test_weather():\n",
    "    print(\"=== 테스트 3: 날씨 질문 ===\") \n",
    "    question = \"What's the weather like in Seoul?\"\n",
    "    \n",
    "    result = react_agent.invoke({\n",
    "        \"messages\": [HumanMessage(content=question)]\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n질문: {question}\")\n",
    "    print(f\"최종 답변: {result['messages'][-1].content}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# 테스트 4: 복합 질문 (여러 도구 사용)\n",
    "def test_complex():\n",
    "    print(\"=== 테스트 4: 복합 질문 ===\")\n",
    "    question = \"If I have 100 dollars and buy 3 items that cost 15 dollars each, how much money do I have left? Also, what's the weather in Tokyo?\"\n",
    "    \n",
    "    # stream 모드로 단계별 과정 확인\n",
    "    print(f\"질문: {question}\\n\")\n",
    "    \n",
    "    for chunk in react_agent.stream(\n",
    "        {\"messages\": [HumanMessage(content=question)]},\n",
    "        stream_mode=\"updates\"\n",
    "    ):\n",
    "        node_name = list(chunk.keys())[0]\n",
    "        if node_name == \"agent\":\n",
    "            message = chunk[node_name][\"messages\"][0]\n",
    "            print(f\"🤖 Agent: {message.content[:100]}...\")\n",
    "            if hasattr(message, 'tool_calls') and message.tool_calls:\n",
    "                for tool_call in message.tool_calls:\n",
    "                    print(f\"   🔧 도구 호출: {tool_call['name']}\")\n",
    "        elif node_name == \"tools\":\n",
    "            tool_messages = chunk[node_name][\"messages\"]\n",
    "            for msg in tool_messages:\n",
    "                if hasattr(msg, 'content'):\n",
    "                    print(f\"   ⚙️  도구 결과: {msg.content}\")\n",
    "        print()\n",
    "\n",
    "# 모든 테스트 실행\n",
    "def run_all_tests():\n",
    "    test_calculation()\n",
    "    test_search()\n",
    "    test_weather() \n",
    "    test_complex()\n",
    "\n",
    "# 테스트 실행\n",
    "run_all_tests()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c5cb0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
