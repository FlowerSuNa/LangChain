{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "803afa3e",
   "metadata": {},
   "source": [
    "# 임베딩 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc94600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from langchain_community.utils.math import cosine_similarity\n",
    "\n",
    "def find_most_similar_index(query_vector, document_vectors):\n",
    "    \"\"\" (코사인 유사도 기준) 가장 유사한 문서 인덱스 반환 함수 \"\"\"\n",
    "    similarities = cosine_similarity([query_vector], document_vectors)[0]\n",
    "    return np.argmax(similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dfb1ca",
   "metadata": {},
   "source": [
    "## OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df5b980",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12222ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb9148f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 임베딩 모델 생성\n",
    "embeddings_openai = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\", # 사용할 모델 이름\n",
    "    dimensions=None,                # 임베딩 차원 수\n",
    ")\n",
    "\n",
    "# 문서 임베딩\n",
    "documents = [\n",
    "    \"LangChain은 LLM 기반 애플리케이션 개발을 위한 프레임워크입니다.\",\n",
    "    \"임베딩은 텍스트를 벡터 형태로 변환하는 작업입니다.\"\n",
    "]\n",
    "document_vectors = embeddings_openai.embed_documents(documents)\n",
    "\n",
    "# 질의 임베딩\n",
    "query_vector = embeddings_openai.embed_query(\"LangChain이란 무엇인가요?\")\n",
    "\n",
    "# 가장 유사한 문서 출력\n",
    "documents[find_most_similar_index(query_vector, document_vectors)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5057dfcd",
   "metadata": {},
   "source": [
    "## HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5589461",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1694a20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings  \n",
    "\n",
    "# 임베딩 모델 생성\n",
    "embeddings_bgem3 = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-m3\",          # 사용할 모델 이름\n",
    "    # model_kwargs={'device': 'cuda'}  # GPU 사용시\n",
    "    # model_kwargs={'device': 'mps'}   # Mac Silicon 사용시\n",
    ")\n",
    "\n",
    "# 문서 임베딩\n",
    "documents = [\n",
    "    \"LangChain은 LLM 기반 애플리케이션 개발을 위한 프레임워크입니다.\",\n",
    "    \"임베딩은 텍스트를 벡터 형태로 변환하는 작업입니다.\"\n",
    "]\n",
    "document_vectors = embeddings_bgem3.embed_documents(documents)\n",
    "\n",
    "# 질의 임베딩\n",
    "query_vector = embeddings_bgem3.embed_query(\"LangChain이란 무엇인가요?\")\n",
    "\n",
    "# 가장 유사한 문서 출력\n",
    "documents[find_most_similar_index(query_vector, document_vectors)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7569fa62",
   "metadata": {},
   "source": [
    "## Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9510259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a92eaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings \n",
    "\n",
    "# 임베딩 모델 생성\n",
    "embeddings_ollama = OllamaEmbeddings(model=\"bge-m3\")\n",
    "\n",
    "# 문서 임베딩\n",
    "documents = [\n",
    "    \"LangChain은 LLM 기반 애플리케이션 개발을 위한 프레임워크입니다.\",\n",
    "    \"임베딩은 텍스트를 벡터 형태로 변환하는 작업입니다.\"\n",
    "]\n",
    "document_vectors = embeddings_ollama.embed_documents(documents)\n",
    "\n",
    "# 질의 임베딩\n",
    "query_vector = embeddings_ollama.embed_query(\"LangChain이란 무엇인가요?\")\n",
    "\n",
    "# 가장 유사한 문서 출력\n",
    "documents[find_most_similar_index(query_vector, document_vectors)]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
