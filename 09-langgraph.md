# LangGraph

- ğŸ”— [Graph API ê°œë…](https://langchain-ai.github.io/langgraph/concepts/low_level/#multiple-schemas) / [LangGraph Studio](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/) / [Functional API](https://langchain-ai.github.io/langgraph/concepts/functional_api/) / [Workflows and Agents](https://langchain-ai.github.io/langgraph/tutorials/workflows/)
- LangGraphëŠ” ì—ì´ì „íŠ¸(Agent) ì›Œí¬í”Œë¡œìš°ë¥¼ ê·¸ë˜í”„ë¡œ ëª¨ë¸ë§í•¨

**í•µì‹¬ êµ¬ì„± ìš”ì†Œ**
-`State`: ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ í˜„ì¬ ìŠ¤ëƒ…ìƒ·ì„ ë‚˜íƒ€ë‚´ëŠ” ê³µìœ  ë°ì´í„° êµ¬ì¡°ë¡œ, ì¼ë°˜ì ìœ¼ë¡œ `TypedDict` ë˜ëŠ” Pydanticì˜ `BaseModel` í˜•íƒœë¥¼ ì‚¬ìš©í•¨
    - ê° ìƒíƒœëŠ” ë‹¤ë¥¸ ìƒíƒœì— ì˜í•´ override(ë®ì–´ì“°ê¸°) ë  ìˆ˜ ìˆì–´ ë°ì´í„°ë¥¼ ìœ ì—°í•˜ê²Œ ê´€ë¦¬í•  ìˆ˜ ìˆìŒ
    - ìƒíƒœ ê´€ë¦¬ë¥¼ í†µí•´ ì²´ê³„ì ì¸ ë°ì´í„° ì²˜ë¦¬ì™€ íë¦„ ì œì–´ ê°€ëŠ¥í•¨
- `Nodes` : ì—ì´ì „íŠ¸ì˜ ë¡œì§ì„ ì¸ì½”ë”©í•˜ë©°, í˜„ì¬ ê°’ì„ `State` ì…ë ¥ìœ¼ë¡œ ë°›ê³ , ê³„ì‚°ì´ë‚˜ ë¶€ìˆ˜ íš¨ê³¼ë¥¼ ìˆ˜í–‰í•œ í›„ ì—…ë°ì´íŠ¸ëœ ê°’ì„ ë°˜í™˜í•¨
    - ë…¸ë“œëŠ” ë…ë¦½ì ì¸ ì‘ì—… ë‹¨ìœ„ë¡œ, íŠ¹ì • í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•¨
    - ê° ë…¸ë“œëŠ” ë‹¤ë¥¸ ë…¸ë“œì™€ ì—°ê²°ë˜ì–´ ë°ì´í„° íë¦„ì„ í˜•ì„±í•¨
    - ìƒíƒœë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ì²˜ë¦¬í•˜ê³  ì—…ë°ì´íŠ¸ëœ ìƒíƒœë¥¼ ë°˜í™˜í•¨
- `Edges` : 

---

## StateGraph
- ìƒíƒœ ê¸°ë°˜ì˜ ê·¸ë˜í”„ êµ¬ì¡°ë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€í™” íë¦„ì„ ì²´ê³„ì ìœ¼ë¡œ ê´€ë¦¬í•˜ëŠ” ê·¸ë˜í”„ í´ë˜ìŠ¤ì„

```python
from typing import TypedDict
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, START, END
from IPython.display import Image, display


# LLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
llm = ChatOpenAI(model="gpt-4.1-mini")

# ìƒíƒœ ì •ì˜
class State(TypedDict):
    original_text: str   # ì›ë³¸ í…ìŠ¤íŠ¸
    summary: str         # ìš”ì•½ë³¸

# ìš”ì•½ ìƒì„± ë…¸ë“œ
def generate_summary(state: State):
    """ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•˜ëŠ” ë…¸ë“œ"""
    # ë¡œì§
    return {"summary": "Summary Content"}

# StateGraph ê°ì²´ ìƒì„± (Workflow)
workflow = StateGraph(State)

# ë…¸ë“œ ì¶”ê°€
workflow.add_node("generate_summary", generate_summary)

# ì—£ì§€ ì¶”ê°€
workflow.add_edge(START, "generate_summary")
workflow.add_edge("generate_summary", END)

# ê·¸ë˜í”„ ì»´íŒŒì¼
graph = workflow.compile()

# ê·¸ë˜í”„ ì‹œê°í™”
display(Image(graph.get_graph().draw_mermaid_png()))
```


---

## Command
- LangGraph í•µì‹¬ ì œì–´ ë„êµ¬ë¡œ, ë…¸ë“œ í•¨ìˆ­ì˜ ë°˜í™˜ê°’ìœ¼ë¡œ ì‚¬ìš©í•¨
- ìƒíƒœ ê´€ë¦¬ì™€ íë¦„ ì œì–´ë¥¼ ë™ì‹œì— ìˆ˜í–‰í•  ìˆ˜ ìˆì–´ íš¨ìœ¨ì ì¸ ê·¸ë˜í”„ ìš´ì˜ì´ ê°€ëŠ¥í•¨
- ê·¸ë˜í”„ì˜ ìƒíƒœë¥¼ ë™ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ë©´ì„œ ë‹¤ìŒ ì‹¤í–‰í•  ë…¸ë“œë¥¼ ì§€ì •í•  ìˆ˜ ìˆìŒ


## Graph API

## Reducer

[](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers)

## Messages

- LangGraphëŠ” ë©”ì‹œì§€ ëª©ë¡ ê¸°ë°˜ì˜ ì±„íŒ… ëª¨ë¸ ì¸í„°í˜ì´ìŠ¤ë¥¼ í™œìš©í•¨
- ê·¸ë˜í”„ ìƒíƒœì—ì„œ ëŒ€í™” ê¸°ë¡ì€ ë©”ì‹œì§€ ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥ë˜ë©°, ì´ë¥¼ í†µí•´ íš¨ìœ¨ì ì¸ ëŒ€í™” ê´€ë¦¬ê°€ ê°€ëŠ¥í•¨
- reducer í•¨ìˆ˜ë¥¼ í†µí•´ ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹œ ë©”ì‹œì§€ ëª©ë¡ì´ ì–´ë–»ê²Œ ê°±ì‹ ë ì§€ ì •ì˜í•  ìˆ˜ ìˆìŒ

`add_messages`
- ë©”ì‹œì§€ IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê¸°ì¡´ ë©”ì‹œì§€ë¥¼ ì—…ë°ì´íŠ¸í•˜ê±°ë‚˜ ìƒˆ ë©”ì‹œì§€ë¥¼ ì¶”ê°€í•˜ëŠ” ê³ ê¸‰ ê´€ë¦¬ ê¸°ëŠ¥ì„ ì œê³µí•¨
- ê¸°ì¡´ ë©”ì‹œì§€ì˜ ì¤‘ë³µ ì¶”ê°€ë¥¼ ë°©ì§€í•¨

`MessagesState`

## Map-Reduce íŒ¨í„´

- ë™ì ìœ¼ë¡œ ì—£ì§€ë¥¼ ìƒì„±í•˜ê³ , ê°œë³„ ìƒíƒœë¥¼ ì „ë‹¬í•˜ëŠ” ë°©ì‹ì„ (ë¶„ì‚°ì²˜ë¦¬)


```python
from typing import Annotated, List, TypedDict, Optional
from pydantic import BaseModel
from langchain_community.tools import DuckDuckGoSearchResults
from langgraph.graph import StateGraph, START, END
from langgraph.types import Send
import operator
from IPython.display import Image, display

# íŒ©íŠ¸ ì²´í¬ ê²°ê³¼ë¥¼ ìœ„í•œ Pydantic ëª¨ë¸
class FactCheckResult(BaseModel):
    sentence: str
    score: float

# ì „ì²´ ìƒíƒœ ì •ì˜ (ê¸€ë¡œë²Œ ìƒíƒœ)
class OverallState(TypedDict):
    query: str  # ê²€ìƒ‰ ì¿¼ë¦¬
    search_results: Optional[str]  # ê²€ìƒ‰ ê²°ê³¼
    summary: Optional[str]  # ìš”ì•½ë¬¸
    fact_check: Annotated[List[FactCheckResult], operator.add]  # íŒ©íŠ¸ì²´í¬ ê²°ê³¼ (ëˆ„ì )

# ë¡œì»¬ ìƒíƒœ (ë‹¨ì¼ ë¬¸ì¥ íŒ©íŠ¸ì²´í¬ìš©)
class SentenceState(TypedDict):
    sentence: str  # íŒ©íŠ¸ì²´í¬í•  ë¬¸ì¥


def search_info(state: OverallState) -> OverallState:
    search_tool = DuckDuckGoSearchResults(output_format="list")
    query = state["query"]

    # ê²€ìƒ‰ ì‹¤í–‰
    results = search_tool.invoke({"query": query})

    # ìƒìœ„ 3ê°œ ê²°ê³¼ë§Œ ì‚¬ìš© (snippet í•„ë“œ)
    filtered_results = [item['snippet'] for item in results][:3]

    return {
        "search_results": filtered_results
    }

def generate_summary(state: OverallState) -> OverallState:
    if not state["search_results"]:
        return {"summary": "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."}

    summary_prompt = """
    ë‹¤ìŒ ê²€ìƒ‰ ê²°ê³¼ë“¤ì„ ìš”ì•½í•´ì£¼ì„¸ìš”:
    {search_results}

    í•µì‹¬ í¬ì¸íŠ¸ 3-4ê°œë¡œ ê°„ë‹¨íˆ ìš”ì•½:
    """

    summary = llm.invoke(summary_prompt.format(
        search_results="\n\n".join(state["search_results"])
    ))

    return {"summary": summary.content}

def fact_check_sentences(state: OverallState):
    if not state["summary"]:
        return {"fact_check": []}

    # ìš”ì•½ëœ ë¬¸ì¥ë“¤ì„ ë¶„ë¦¬ (ê°„ë‹¨í•˜ê²Œ ê°œí•­ë¬¸ìë¡œ ë¶„ë¦¬)
    sentences = state["summary"].split("\n\n")
    sentences = [s.strip() for s in sentences if s.strip()]  # ë¹ˆ ë¬¸ìì—´ ì œê±°

    print(f"Fact-checking {len(sentences)} sentences...")

    # ê° ë¬¸ì¥ì— ëŒ€í•´ íŒ©íŠ¸ ì²´í¬ ì‘ì—…ì„ ìƒì„± (Send ì‚¬ìš©)
    return [
        Send("fact_check_sentence", {"sentence": s}) for s in sentences
    ]

def fact_check_single_sentence(state: SentenceState) -> OverallState:
    """ê°œë³„ ë¬¸ì¥ì— ëŒ€í•œ íŒ©íŠ¸ì²´í¬ ìˆ˜í–‰"""
    sentence = state["sentence"]
    print(f"Fact-checking sentence: {sentence}")

    prompt = f"""
    ë‹¤ìŒ ë¬¸ì¥ì˜ ì‚¬ì‹¤ ì—¬ë¶€ë¥¼ í‰ê°€í•˜ê³  ì‹ ë¢°ë„ ì ìˆ˜ë¥¼ 0ê³¼ 1 ì‚¬ì´ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
    ë¬¸ì¥: {sentence}
    ì‹ ë¢°ë„ ì ìˆ˜:
    """
    response = llm.invoke(prompt)

    # íŒ©íŠ¸ì²´í¬ ê²°ê³¼ ìƒì„±
    print(f"Fact-check result: {response.content}")
    
    try:
        score = float(response.content)
        score = max(0.0, min(1.0, score))  # 0ê³¼ 1 ì‚¬ì´ë¡œ ì œí•œ
    except ValueError:
        score = 0.5  # ê¸°ë³¸ê°’
    
    return {
        "fact_check": [FactCheckResult(sentence=sentence, score=score)]
    }

# ê·¸ë˜í”„ êµ¬ì„±
builder = StateGraph(OverallState)

# ë…¸ë“œ ì¶”ê°€
builder.add_node("search", search_info)
builder.add_node("generate_summary", generate_summary)
builder.add_node("fact_check_sentence", fact_check_single_sentence)

# ì—£ì§€ ì¶”ê°€
builder.add_edge(START, "search")
builder.add_edge("search", "generate_summary")
builder.add_conditional_edges(
    "generate_summary",
    fact_check_sentences,
    ["fact_check_sentence"]
)

builder.add_edge("fact_check_sentence", END)

# ê·¸ë˜í”„ ì»´íŒŒì¼
graph = builder.compile()

# ê·¸ë˜í”„ ì‹œê°í™”
display(Image(graph.get_graph().draw_mermaid_png()))

# ì‚¬ìš©ì ì§ˆë¬¸
inputs = {"query": "ê¸°í›„ ë³€í™”ì˜ ì£¼ìš” ì›ì¸ì€ ë¬´ì—‡ì¸ê°€ìš”?"}

# ê·¸ë˜í”„ ì‹¤í–‰
result = graph.invoke(inputs)
pprint(result)
```

## Tool Node

- ëª¨ë¸ì´ ì‚¬ì „ì— ì •ì˜ëœ ë„êµ¬ í˜¸ì¶œì„ ì‹¤í–‰í•˜ëŠ” ì—­í• í•˜ëŠ” LangGraph êµ¬ì„±ìš”ì†Œì„

```python
from langgraph.prebuilt import ToolNode

# ë„êµ¬ ë…¸ë“œ ì •ì˜
db_tool_node = ToolNode(tools=tools)

# LLM ëª¨ë¸ ìƒì„±
llm = ChatOpenAI(model="gpt-4.1-mini", temperature=0)

# ë„êµ¬ë¥¼ ë°”ì¸ë”©í•˜ì—¬ ëª¨ë¸ ìƒì„±
llm_with_tools = llm.bind_tools(tools=tools)

# ë„êµ¬ í˜¸ì¶œ - í•œêµ­ì–´
tool_call = llm_with_tools.invoke([HumanMessage(content=f"í…ŒìŠ¬ë¼ëŠ” ëˆ„ê°€ ì°½ë¦½í–ˆë‚˜ìš”?")])

# ë„êµ¬ í˜¸ì¶œ ë‚´ìš© ì¶œë ¥
pprint(tool_call.tool_calls)
print("-" * 100)

# ë„êµ¬ í˜¸ì¶œ ê²°ê³¼ë¥¼ ë©”ì‹œì§€ë¡œ ì¶”ê°€í•˜ì—¬ ì‹¤í–‰
results = db_tool_node.invoke({"messages": [tool_call]})

# ì‹¤í–‰ ê²°ê³¼ ì¶œë ¥í•˜ì—¬ í™•ì¸
for result in results['messages']:
    print(f"ë©”ì‹œì§€ íƒ€ì…: {type(result)}")
    print(f"ë©”ì‹œì§€ ë‚´ìš©: {result.content}")
    print()
```

## ReAct Agent (Reasoning and Acting)

- ê°€ì¥ ì¼ë°˜ì ì¸ ì—ì´ì „íŠ¸ë¡œ, ëª¨ë¸ì´ íŠ¹ì • ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ê³  ì¶œë ¥ì„ ë‹¤ì‹œ ëª¨ë¸ì— ì „ë‹¬í•˜ëŠ” ê³¼ì •ì„ ê±°ì¹¨
- ëª¨ë¸ì´ ë„êµ¬ ì¶œë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ í–‰ë™ì„ ê²°ì •í•¨
- ë°˜ë³µë˜ëŠ” ê³¼ì •ì—ì„œ ë˜ ë‹¤ë¥¸ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ê±°ë‚˜ ì§ì ‘ ì‘ë‹µì„ ìƒì„±í•¨

## MemorySaver

- [LangGraph Memory](https://langchain-ai.github.io/langgraph/concepts/memory/)
- LangGraphì—ì„œ ì œê³µí•˜ëŠ” ìŠ¤ë ˆë“œ ê¸°ë°˜ì˜ ë‹¨ê¸° ë©”ëª¨ë¦¬(short-term memory)ë¡œ, í•˜ë‚˜ì˜ ëŒ€í™” ì„¸ì…˜ ë™ì•ˆë§Œ ì •ë³´ë¥¼ ìœ ì§€í•¨
- ì—ì´ì „íŠ¸ì˜ ìƒíƒœë¡œ ë‹¨ê¸° ë©”ëª¨ë¦¬ë¥¼ ê´€ë¦¬í•˜ë©°, ì²´í¬í¬ì¸í„°ë¥¼ í†µí•´ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ë¨
- ë©”ëª¨ë¦¬ëŠ” ê·¸ë˜í”„ ì‹¤í–‰ ë˜ëŠ” ë‹¨ê³„ ì™„ë£Œ ì‹œ ì—…ë°ì´íŠ¸ ë˜ë©°, ê° ë‹¨ê³„ ì‹œì‘ ì‹œ ìƒíƒœë¥¼ ì½ì–´ë“¤ì„


### Checkpoints